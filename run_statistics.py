import os
import json
import numpy as np
from glob import glob
from pybeh.spc import spc
from pybeh.pnr import pnr
from pybeh.crp import crp
from pybeh.irt import irt
from pybeh.crl import crl
# from pybeh.temp_fact import temp_fact
# from pybeh.dist_fact import dist_fact
# from pybeh.sem_crp import sem_crp
# from scipy.io import loadmat


def run_stats():
    data_files = glob('/Users/jessepazdera/Desktop/behavioral/beh_data_LTP[0-9][0-9][0-9].json') + \
                 glob('/Users/jessepazdera/Desktop/behavioral/beh_data_LTP[0-9][0-9][0-9]_incomplete.json')

    stats = dict()
    for path in data_files:
        subj = os.path.basename(path)[9:15]
        complete = not path.endswith('incomplete.json')

        with open(path, 'r') as f:
            # Run all stats for a single participant and add the resulting stats object to the stats dictionary
            stats[str(subj)] = stats_for_subj(json.load(f), complete=complete)

    return stats


def stats_for_subj(data, complete=True):
    outfile = '/Users/jessepazdera/Desktop/stats/stats_%s.json' % data['subject'][0] if complete else '/Users/jessepazdera/Desktop/stats/stats_%s_incomplete.json' % data['subject'][0]

    good_trials = np.logical_not(np.array(data['bad_list']))

    sessions = np.array(data['session'])[good_trials]
    recalled = np.array(data['recalled'])[good_trials]
    spos = np.array(data['serialpos'])[good_trials]
    times = np.array(data['times'])[good_trials]
    intru = np.array(data['intrusions'])[good_trials]
    recw = np.array(data['rec_words'])[good_trials]
    ll = len(data['pres_nos'][0])[good_trials]
    # pres_nos = np.array(data['pres_nos'])[good_trials]
    # rec_nos = np.array(data['rec_nos'])[good_trials]
    # lsa = loadmat('pybeh/LSA.mat')['LSA']

    stats = dict()
    stats['prec'] = prec(recalled, sessions)
    stats['spc'] = spc(spos, sessions, ll)
    stats['pfr'] = pnr(spos, sessions, ll, n=0)
    stats['psr'] = pnr(spos, sessions, ll, n=1)
    stats['ptr'] = pnr(spos, sessions, ll, n=2)
    stats['crp'] = crp(spos, sessions, ll, lag_num=ll-1)
    stats['crl'] = crl(spos, times, sessions, ll, lag_num=ll-1)
    stats['irt'] = irt(times)
    stats['pli_perlist'] = avg_pli(intru, sessions, recw)
    stats['eli_perlist'] = avg_eli(intru, sessions)
    stats['reps_perlist'] = avg_reps(spos, sessions)
    # stats['temp_fact'] = temp_fact(spos, sessions, ll)
    # stats['dist_fact'] = dist_fact(rec_nos, pres_nos, sessions, lsa, ll)
    # stats['sem_crp'] = sem_crp(spos, rec_nos, pres_nos, sessions, lsa, 10, ll)
    # stats['pli_recency'] = nback_pli(intru, sessions, 6, recw)[0]

    # Convert numpy arrays to lists, so that they are JSON serializable
    for stat in stats:
        if isinstance(stats[stat], np.ndarray):
            stats[stat] = stats[stat].tolist()

    with open(outfile, 'w') as f:
        json.dump(stats, f)

    return stats


def prec(was_recalled, subjects):
    """
    Calculate the overall probability of recall for each subject, given a lists x items matrix where 0s indicate
    words that were not subsequently recalled and 1s indicate words that were subsequently recalled. Item (i, j)
    should indicate whether the jth word presented in list i was recalled.

    :param was_recalled: A lists x items matrix, indicating whether each presented word was subsequently recalled
    :param subjects: A list of subject codes, indicating which subject produced each row of was_recalled
    :return: An array containing the overall probability of recall for each unique participant
    """
    if len(was_recalled) == 0:
        return np.array([]), np.array([])
    usub = np.unique(subjects)
    result = np.zeros(len(usub))
    for i, s in enumerate(usub):
        result[i] = float(len(np.where(was_recalled[np.where(subjects == s)] == 1)[0])) / len(
            np.where(np.logical_not(np.isnan(was_recalled[np.where(subjects == s)])))[0])

    return result


def avg_pli(intrusions, subjects, rec_itemnos):
    """
    A modification of the behavioral toolbox's pli function. Calculate's each partcipant's average number of PLIs per
    list instead of their total number of PLIs.

    :param intrusions: An intrusions matrix in the format generated by recalls_to_intrusions
    :param subjects: A list of subject codes, indicating which subject produced each row of the intrusions matrix
    :param rec_itemnos: A matrix in which each row is the list of IDs for all words recalled by a single subject on a
                        single trial. Rows are expected to be padded with 0s to all be the same length.
    :return: An array where each entry is the average number of PLIs per list for a single participant.
    """
    usub = np.unique(subjects)
    result = np.zeros(len(usub))
    for subject_index in range(len(usub)):
        count = 0.
        lists = 0.
        for subj in range(len(subjects)):
            if subjects[subj] == usub[subject_index]:
                lists += 1
                encountered = []
                for serial_pos in range(len(intrusions[0])):
                    if intrusions[subj][serial_pos] > 0 and rec_itemnos[subj][serial_pos] not in encountered:
                        count += 1
                        encountered.append(rec_itemnos[subj][serial_pos])
        result[subject_index] = count / lists if lists > 0 else np.nan

    return result


def avg_eli(intrusions=None, subjects=None):
    """
    A modification of the behavioral toolbox's xli function. Calculate's each partcipant's average number of ELIs per
    list instead of their total number of ELIs.
    :param intrusions: An intrusions matrix in the format generated by recalls_to_intrusions
    :param subjects: A list of subject codes, indicating which subject produced each row of the intrusions matrix
    :return: An array where each entry is the average number of PLIs per list for a single participant.
    """
    usub = np.unique(subjects)
    result = np.zeros(len(usub))
    for subject_index in range(len(usub)):
        count = 0.
        lists = 0.
        for subj in range(len(subjects)):
            if subjects[subj] == usub[subject_index]:
                lists += 1
                for serial_pos in range(len(intrusions[0])):
                    if intrusions[subj][serial_pos] < 0:
                        count += 1
        result[subject_index] = count / lists if lists > 0 else np.nan
    return result


def avg_reps(rec_itemnos, subjects):
    """
    Calculate's each partcipant's average number of repetitions per list.

    :param rec_itemnos: A matrix in which each row is the list of IDs for all words recalled by a single subject on a
                        single trial. Rows are expected to be padded with 0s to all be the same length.
    :param subjects: A list of subject codes, indicating which subject produced each row of the intrusions matrix
    :return: An array where each entry is the average number of repetitions per list for a single participant.
    """
    usub = np.unique(subjects)
    result = np.zeros(len(usub))
    for subject_index in range(len(usub)):
        count = 0.
        lists = 0.
        for subj in range(len(subjects)):
            if subjects[subj] == usub[subject_index]:
                lists += 1
                # times_recalled is an array with one entry for each unique correctly recalled word, indicating the
                # number of times that word was recalled during the current list
                times_recalled = np.array(
                    [len(np.where(rec_itemnos[subj, :] == rec)[0]) for rec in np.unique(rec_itemnos[subj, :]) if
                     rec > 0])
                # Subtract 1 from the number of times each correct word was recalled in the list to give the number of
                # repetitions
                repetitions = times_recalled - 1
                # Sum the number of repetitions made in the current list
                count += repetitions.sum()
        result[subject_index] = count / lists if lists > 0 else np.nan
    return result


if __name__ == "__main__":
    run_stats()
